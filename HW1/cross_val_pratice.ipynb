{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_w , y_w= fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_yt = testmy_cross_val(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_yt = testmy_cross_val(X_w, y_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "nst_df = new_yt.drop(new_yt.columns[1], axis = 1)\n",
    "workd_df = work_yt.drop(work_yt.columns[1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.empty((0, len(target_fold.iloc[0])))\n",
    "for j in range(target_fold.shape[0]):\n",
    "    df = np.row_stack([df, target_fold.iloc[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_target_fold (nested_df):\n",
    "    final_df = np.empty((0, len(nested_df.iloc[0, 0])))\n",
    "    for i in range(nested_df.shape[1]):\n",
    "        df = np.empty((0, len(nested_df.iloc[0, 0])))\n",
    "        for j in range(nested_df.shape[0]):\n",
    "            df = np.row_stack([df, nested_df.iloc[j, i]])\n",
    "        \n",
    "        final_df = np.row_stack([final_df, df])\n",
    "        final_df = pd.DataFrame(final_df)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_val(model, loss_func, X, y, k=10):\n",
    "    dataset = np.column_stack([X, y])\n",
    "    split_data = []\n",
    "    copy = list(dataset)\n",
    "    size_each_fold = int(len(copy) / k)\n",
    "\n",
    "    for i in range(k):\n",
    "        fold = []\n",
    "        while len(fold) < size_each_fold:\n",
    "            index = random.randrange(len(copy))\n",
    "            fold.append(copy.pop(index))\n",
    "        split_data.append(fold)\n",
    "    split_data = pd.DataFrame(split_data)\n",
    "    split_data = split_data.transpose()\n",
    "    #return split_data\n",
    "    mse_by_fold = []\n",
    "    err_rate_by_fold = []   \n",
    "    for i in range(k):\n",
    "        target_fold = split_data.iloc[:, i]\n",
    "        df = np.empty((0, len(target_fold.iloc[0])))\n",
    "        for j in range(target_fold.shape[0]):\n",
    "            df = np.row_stack([df, target_fold.iloc[j]])\n",
    "        df = pd.DataFrame(df)\n",
    "        non_fold = non_target_fold(split_data.drop(split_data.columns[i], axis = 1))\n",
    "        X_fold = df.iloc[:, :-1]\n",
    "        y_fold = df.iloc[:, -1:]\n",
    "        X_non_fold = non_fold.iloc[:, :-1]\n",
    "        y_non_fold = non_fold.iloc[:, -1:]\n",
    "        y_fold = y_fold.to_numpy()\n",
    "        y_fold = y_fold.reshape((len(y_fold), ))\n",
    "        y_non_fold = y_non_fold.to_numpy()\n",
    "        y_non_fold = y_non_fold.reshape((len(y_non_fold), ))\n",
    "\n",
    "        model_fitted = model.fit(X_non_fold, y_non_fold)\n",
    "        if loss_func == 'mse':\n",
    "            #mse_by_fold = []\n",
    "            mse = np.mean((y_fold - model_fitted.predict(X_fold))**2)\n",
    "            mse_by_fold.append(mse)\n",
    "        elif loss_func == 'err_rate':\n",
    "            #err_rate_by_fold = []\n",
    "            y_hat = model_fitted.predict(X_fold)\n",
    "            #return y_hat\n",
    "\n",
    "            err_rate_bool = y_fold != y_hat\n",
    "            err_rate = sum(err_rate_bool)/len(y_fold)\n",
    "            err_rate_by_fold.append(err_rate)\n",
    " \n",
    "    if loss_func == 'mse':\n",
    "        summary = [np.mean(mse_by_fold), np.std(mse_by_fold)]\n",
    "        mse_by_fold.extend(summary)\n",
    "        return mse_by_fold\n",
    "    elif loss_func == 'err_rate':\n",
    "        summary = [np.mean(err_rate_by_fold), np.std(err_rate_by_fold)]\n",
    "        err_rate_by_fold.extend(summary)\n",
    "        return err_rate_by_fold    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmy_cross_val(X, y, k=10):\n",
    "    dataset = np.column_stack([X, y])\n",
    "    split_data = []\n",
    "    copy = list(dataset)\n",
    "    size_each_fold = int(len(copy) / k)\n",
    "\n",
    "    for i in range(k):\n",
    "        fold = []\n",
    "        while len(fold) < size_each_fold:\n",
    "            index = random.randrange(len(copy))\n",
    "            fold.append(copy.pop(index))\n",
    "        split_data.append(fold)\n",
    "    split_data = pd.DataFrame(split_data)\n",
    "    split_data = split_data.transpose()\n",
    "    #return split_data\n",
    "    mse_by_fold = []\n",
    "    err_rate_by_fold = []   \n",
    "    for i in range(k):\n",
    "        target_fold = split_data.iloc[:, i]\n",
    "        df = np.empty((0, len(target_fold.iloc[0])))\n",
    "        for j in range(target_fold.shape[0]):\n",
    "            df = np.row_stack([df, target_fold.iloc[j]])\n",
    "        df = pd.DataFrame(df)\n",
    "        non_fold = non_target_fold(split_data.drop(split_data.columns[i], axis = 1))\n",
    "        df = df.reset_index(drop = True)\n",
    "        non_fold = non_fold.reset_index(drop = True)\n",
    "        X_fold = df.iloc[:, :-1]\n",
    "        y_fold = df.iloc[:, -1:]\n",
    "        X_non_fold = non_fold.iloc[:, :-1]\n",
    "        y_non_fold = non_fold.iloc[:, -1:]\n",
    "        y_fold = y_fold.to_numpy()\n",
    "        y_fold = y_fold.reshape((len(y_fold), ))\n",
    "        y_non_fold = y_non_fold.to_numpy()\n",
    "        y_non_fold = y_non_fold.reshape((len(y_non_fold), ))\n",
    "    return X_fold, y_fold, X_non_fold, y_non_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfold, yfold, xfit, yfit = testmy_cross_val(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = yfold.to_numpy()\n",
    "y_np_re = y_np.reshape((len(y_np), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = new_yt.iloc[0, 0]\n",
    "t1 = new_yt.iloc[1, 0]\n",
    "t2 = new_yt.iloc[2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.row_stack([t0, t1, t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_yt.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.empty((0, len(new_yt.iloc[0, 1])))\n",
    "for i in range(new_yt.shape[0]):\n",
    "    df = np.row_stack([df, new_yt.iloc[i, 0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression CV MSE values [8    0.521443\n",
      "dtype: float64, 8    0.512555\n",
      "dtype: float64, 8    0.555628\n",
      "dtype: float64, 8    0.531736\n",
      "dtype: float64, 8    0.495136\n",
      "dtype: float64, 8    0.506276\n",
      "dtype: float64, 8    0.534421\n",
      "dtype: float64, 8    0.525984\n",
      "dtype: float64, 8    0.558649\n",
      "dtype: float64, 8    0.536008\n",
      "dtype: float64, 0.5277836094952904, 0.019128863610841824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# instantiate ridge regression object\n",
    "rr_model = Ridge(alpha=0.01)\n",
    "\n",
    "# call to your CV function\n",
    "mse_vals = my_cross_val(rr_model, 'mse', X, y, k=10)\n",
    "\n",
    "print('Ridge regression CV MSE values', mse_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fold, y_fold, x_fit, y_fit = testmy_cross_val(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV error rates [0.017857142857142856, 0.07142857142857142, 0.07142857142857142, 0.08928571428571429, 0.03571428571428571, 0.08928571428571429, 0.03571428571428571, 0.03571428571428571, 0.017857142857142856, 0.03571428571428571, 0.049999999999999996, 0.026244532958391194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kimsh96453/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# instantiate logistic regression object\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "\n",
    "# call to your CV function\n",
    "err_rates = my_cross_val(lr_model, 'err_rate', X, y, k=10)\n",
    "\n",
    "print('Logistic Regression CV error rates', err_rates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65e26a417bba122887fd29982395cb2c5358c401a000d55be7838ee8c3bbdd30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
